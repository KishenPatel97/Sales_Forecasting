{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def plot_features(booster, figsize):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    return plot_importance(booster=booster, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down casts the data entries from int64 to int32 and float64 to float32\n",
    "# This reduces the size of the records by almost half. (From 134mb to 61mb)\n",
    "def downcast_dtypes(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols = [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols] = df[int_cols].astype(np.int16)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and clean data (importing csv into pandas)\n",
    "# Read in .csv files into pandas data frames\n",
    "month_group2 = pd.read_csv('month_lag_grouped.csv')\n",
    "# test = pd.read_csv('test.csv').set_index('ID')\n",
    "# submission = pd.read_csv('sample_submission.csv')\n",
    "items = pd.read_csv('items.csv')\n",
    "#item_cats = pd.read_csv('item_categories.csv')\n",
    "# shops = pd.read_csv('shops.csv')\n",
    "#items_t = pd.read_csv('items_translated_text.csv')\n",
    "train_lag = pd.read_csv('new_month_group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls the downcasting function\n",
    "month_group2 = downcast_dtypes(train)\n",
    "# test = downcast_dtypes(test)\n",
    "# submission = downcast_dtypes(submission)\n",
    "items = downcast_dtypes(items)\n",
    "train_lag = downcast_dtypes(train_lag)\n",
    "\n",
    "#item_cats = downcast_dtypes(item_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to tranform prediction inputs\n",
    "ct = ColumnTransformer([('encoder', OneHotEncoder(), [0, 1, 2, 3])], remainder='passthrough')\n",
    "x = train_lag.iloc[:, :-1].values\n",
    "ct.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z_list(shop_id_num, item_id_num):\n",
    "    # item_cat = items.loc[items['item_id'] == item_id_num, ['item_category_id']].values[0][0]\n",
    "    item_cat = items[items['item_id'] == item_id_num]['item_category_id'].values\n",
    "    prices = train.loc[train['item_id'] == item_id_num, ['item_price']].values\n",
    "    price = (stats.mode(prices))[0][0][0]\n",
    "    date_num = 34\n",
    "    new_pd = month_group2.loc[month_group2['date_block_num'] == date_num-1].loc[month_group2['shop_id'] == shop_id_num].loc[month_group2['item_id'] == item_id_num]\n",
    "    new_pd2 = month_group2.loc[month_group2['date_block_num'] == date_num-2].loc[month_group2['shop_id'] == shop_id_num].loc[month_group2['item_id'] == item_id_num]\n",
    "    new_pd3 = month_group2.loc[month_group2['date_block_num'] == date_num-3].loc[month_group2['shop_id'] == shop_id_num].loc[month_group2['item_id'] == item_id_num]\n",
    "    new_pd4 = month_group2.loc[month_group2['date_block_num'] == date_num-4].loc[month_group2['shop_id'] == shop_id_num].loc[month_group2['item_id'] == item_id_num]\n",
    "    new_pd5 = month_group2.loc[month_group2['date_block_num'] == date_num-5].loc[month_group2['shop_id'] == shop_id_num].loc[month_group2['item_id'] == item_id_num]\n",
    "    #print(len(new_pd['date_block_num']))\n",
    "    if len(new_pd['shop_id']) > 0:\n",
    "        mon1 = month_group2['item_cnt_day'][new_pd.index[0]]\n",
    "    else:\n",
    "        mon1 = 0\n",
    "\n",
    "    if len(new_pd2['shop_id']) > 0:\n",
    "        mon2 = month_group2['item_cnt_day'][new_pd2.index[0]]\n",
    "    else:\n",
    "        mon2 = 0\n",
    "\n",
    "    if len(new_pd3['shop_id']) > 0:\n",
    "        mon3 = month_group2['item_cnt_day'][new_pd3.index[0]]\n",
    "    else:\n",
    "        mon3 = 0\n",
    "\n",
    "    if len(new_pd4['shop_id']) > 0:\n",
    "        mon4 = month_group2['item_cnt_day'][new_pd4.index[0]]\n",
    "    else:\n",
    "        mon4 = 0\n",
    "\n",
    "    if len(new_pd5['shop_id']) > 0:\n",
    "        mon5 = month_group2['item_cnt_day'][new_pd5.index[0]]\n",
    "    else:\n",
    "        mon5 = 0\n",
    "\n",
    "    z = ['november', 'shop ' + str(shop_id_num), 'item_category ' + str(item_cat), 'item ' + str(item_id_num), price, mon1, mon2, mon3, mon4, mon5]\n",
    "    return z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
